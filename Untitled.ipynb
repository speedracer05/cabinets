{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4cfb2e7-8920-4f38-8779-c6b693dbb7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libararies\n",
    "import time\n",
    "import csv\n",
    "import logging\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# -------------------------\n",
    "# Logging configuration\n",
    "# -------------------------\n",
    "logging.basicConfig(\n",
    "    filename='scraping_errors.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Set up Selenium WebDriver using webdriver_manager\n",
    "# -------------------------\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # run in headless mode; comment out if debugging\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "wait = WebDriverWait(driver, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1d7c951-2eb1-41b2-88c8-50266e7e5d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Helper Function: Safe extraction for Selenium elements using XPath\n",
    "# -------------------------\n",
    "def safe_extract(driver, xpath, default=\"0\"):\n",
    "    try:\n",
    "        element = driver.find_element(By.XPATH, xpath)\n",
    "        text = element.text.strip()\n",
    "        return text if text else default\n",
    "    except NoSuchElementException:\n",
    "        logging.error(f\"Element not found for XPath: {xpath}\")\n",
    "        return default\n",
    "\n",
    "def safe_extract_attribute(driver, xpath, attribute, default=\"0\"):\n",
    "    try:\n",
    "        element = driver.find_element(By.XPATH, xpath)\n",
    "        attr_val = element.get_attribute(attribute)\n",
    "        return attr_val.strip() if attr_val else default\n",
    "    except NoSuchElementException:\n",
    "        logging.error(f\"Element not found for XPath (attribute {attribute}): {xpath}\")\n",
    "        return default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3a8b295-f026-4aa2-a536-2eea93aec26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Main Scraper Configuration\n",
    "# -------------------------\n",
    "base_exhibitors_url = \"https://kbis2025.smallworldlabs.com/exhibitors\"\n",
    "output_csv = r\"C:\\Users\\jchan\\csi360_fire_police\\cabinet_vendors_list\\cabinets\\resources\\output\\vendor_list.csv\"\n",
    "exhibitor_data = []\n",
    "\n",
    "try:\n",
    "    # 1. Load the exhibitors page and wait for dynamic content\n",
    "    logging.info(f\"Loading exhibitors page: {base_exhibitors_url}\")\n",
    "    driver.get(base_exhibitors_url)\n",
    "    wait.until(EC.presence_of_all_elements_located((By.XPATH, \"//a[contains(@href, '/co/')]\")))\n",
    "    \n",
    "    # 2. Collect unique exhibitor URLs\n",
    "    exhibitor_elements = driver.find_elements(By.XPATH, \"//a[contains(@href, '/co/')]\")\n",
    "    exhibitor_urls = []\n",
    "    for elem in exhibitor_elements:\n",
    "        url = elem.get_attribute('href')\n",
    "        if url and url not in exhibitor_urls:\n",
    "            exhibitor_urls.append(url)\n",
    "    \n",
    "    logging.info(f\"Found {len(exhibitor_urls)} exhibitor links.\")\n",
    "    \n",
    "    # 3. Iterate through each exhibitor page and extract data\n",
    "    for url in exhibitor_urls:\n",
    "        logging.info(f\"Processing exhibitor page: {url}\")\n",
    "        driver.get(url)\n",
    "        \n",
    "        try:\n",
    "            wait.until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "        except TimeoutException:\n",
    "            logging.error(f\"Timeout loading page: {url}\")\n",
    "            continue  # Skip this exhibitor if page doesn't load in time\n",
    "        \n",
    "        # Initialize data dictionary with default values\n",
    "        data = {\n",
    "            \"Company Name\": safe_extract(driver, \"//h1\"),\n",
    "            \"Description\": safe_extract(driver, \"//*[contains(text(),'What They Do')]/following-sibling::*\"),\n",
    "            \"Founded\": safe_extract(driver, \"//*[contains(text(),'Founded')]/following-sibling::*\"),\n",
    "            \"Website\": safe_extract_attribute(driver, \"//*[contains(text(),'Website')]/following-sibling::a\", \"href\"),\n",
    "            \"Categories\": safe_extract(driver, \"//*[contains(text(),'Categories')]/following-sibling::*\"),\n",
    "            \"Key Words\": safe_extract(driver, \"//*[contains(text(),'Key Words')]/following-sibling::*\")\n",
    "        }\n",
    "        exhibitor_data.append(data)\n",
    "        \n",
    "        # 5. Wait 2 seconds between requests\n",
    "        time.sleep(2)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"An error occurred during scraping: {str(e)}\")\n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba183107-5d38-4e1b-8617-fbf1f7573a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping completed. Data saved to C:\\Users\\jchan\\csi360_fire_police\\cabinet_vendors_list\\cabinets\\resources\\output\\vendor_list.csv.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Save extracted data to CSV\n",
    "# -------------------------\n",
    "csv_headers = [\"Company Name\", \"Description\", \"Founded\", \"Website\", \"Categories\", \"Key Words\"]\n",
    "with open(output_csv, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=csv_headers)\n",
    "    writer.writeheader()\n",
    "    for item in exhibitor_data:\n",
    "        writer.writerow(item)\n",
    "\n",
    "logging.info(f\"Scraping completed. Data saved to {output_csv}.\")\n",
    "print(f\"Scraping completed. Data saved to {output_csv}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b22daf1-5dfa-4620-8837-d8e6ce513eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
